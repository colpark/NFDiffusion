{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: Latent Diffusion + Neural Field Decoder\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the simplest baseline approach for merging neural fields with diffusion models:\n",
    "\n",
    "```\n",
    "Sparse Input â†’ Encoder â†’ Latent z\n",
    "    â†“\n",
    "Diffusion Process â†’ z_0 (denoised latent)\n",
    "    â†“\n",
    "Neural Field Decoder(coords, z_0) â†’ Continuous Output\n",
    "```\n",
    "\n",
    "## Why Start Here?\n",
    "\n",
    "- **Easiest to implement**: Well-understood components\n",
    "- **Debuggable**: Can test each component separately\n",
    "- **Foundation**: Concepts transfer to more complex approaches\n",
    "\n",
    "## Toy Problem: 1D Signal Reconstruction\n",
    "\n",
    "We'll use a simple 1D problem to validate the approach:\n",
    "- **Input**: Sparse samples from a 1D signal (e.g., sine wave + noise)\n",
    "- **Goal**: Reconstruct continuous signal at arbitrary resolution\n",
    "- **Sparse Pattern**: Random 20% of points observed\n",
    "\n",
    "## Architecture Components\n",
    "\n",
    "1. **Encoder**: MLP that maps sparse observations â†’ latent code z\n",
    "2. **Neural Field**: SIREN network f(x, z) that maps coordinates + latent â†’ values\n",
    "3. **Diffusion**: Simple DDPM on latent codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation: 1D Signals with Sparse Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_signal(n_points=256, signal_type='sine_mix'):\n",
    "    \"\"\"\n",
    "    Generate various 1D signals for testing\n",
    "    \n",
    "    Args:\n",
    "        n_points: Number of sample points\n",
    "        signal_type: 'sine_mix', 'square', 'triangle', 'random_fourier'\n",
    "    \n",
    "    Returns:\n",
    "        coords: (n_points,) normalized coordinates in [0, 1]\n",
    "        values: (n_points,) signal values\n",
    "    \"\"\"\n",
    "    coords = np.linspace(0, 1, n_points)\n",
    "    \n",
    "    if signal_type == 'sine_mix':\n",
    "        # Mix of sine waves with different frequencies\n",
    "        values = (\n",
    "            0.5 * np.sin(2 * np.pi * coords * 2) +\n",
    "            0.3 * np.sin(2 * np.pi * coords * 5) +\n",
    "            0.2 * np.sin(2 * np.pi * coords * 10)\n",
    "        )\n",
    "    elif signal_type == 'square':\n",
    "        values = np.sign(np.sin(2 * np.pi * coords * 3))\n",
    "    elif signal_type == 'triangle':\n",
    "        values = 2 * np.abs(2 * (coords * 4 - np.floor(coords * 4 + 0.5))) - 1\n",
    "    elif signal_type == 'random_fourier':\n",
    "        # Random Fourier series\n",
    "        np.random.seed(42)\n",
    "        n_freqs = 10\n",
    "        values = np.zeros_like(coords)\n",
    "        for k in range(1, n_freqs + 1):\n",
    "            amp = np.random.randn() * (1 / k)\n",
    "            phase = np.random.rand() * 2 * np.pi\n",
    "            values += amp * np.sin(2 * np.pi * k * coords + phase)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown signal type: {signal_type}\")\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    values = values / (np.abs(values).max() + 1e-8)\n",
    "    \n",
    "    return coords.astype(np.float32), values.astype(np.float32)\n",
    "\n",
    "\n",
    "class Sparse1DDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of 1D signals with sparse observations\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, n_points=256, sparsity=0.2, signal_types=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_samples: Number of different signals\n",
    "            n_points: Resolution of each signal\n",
    "            sparsity: Fraction of points observed (0.2 = 20% observed)\n",
    "            signal_types: List of signal types to sample from\n",
    "        \"\"\"\n",
    "        self.n_samples = n_samples\n",
    "        self.n_points = n_points\n",
    "        self.sparsity = sparsity\n",
    "        self.n_observed = int(n_points * sparsity)\n",
    "        \n",
    "        if signal_types is None:\n",
    "            signal_types = ['sine_mix', 'random_fourier']\n",
    "        self.signal_types = signal_types\n",
    "        \n",
    "        # Pre-generate all signals for reproducibility\n",
    "        self.signals = []\n",
    "        np.random.seed(42)\n",
    "        for i in range(n_samples):\n",
    "            signal_type = np.random.choice(signal_types)\n",
    "            coords, values = generate_1d_signal(n_points, signal_type)\n",
    "            self.signals.append((coords, values))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        coords, values = self.signals[idx]\n",
    "        \n",
    "        # Random sparse sampling\n",
    "        observed_idxs = np.random.choice(\n",
    "            self.n_points, \n",
    "            size=self.n_observed, \n",
    "            replace=False\n",
    "        )\n",
    "        observed_idxs = np.sort(observed_idxs)\n",
    "        \n",
    "        sparse_coords = coords[observed_idxs]\n",
    "        sparse_values = values[observed_idxs]\n",
    "        \n",
    "        return {\n",
    "            'sparse_coords': torch.from_numpy(sparse_coords),  # (n_observed,)\n",
    "            'sparse_values': torch.from_numpy(sparse_values),  # (n_observed,)\n",
    "            'full_coords': torch.from_numpy(coords),           # (n_points,)\n",
    "            'full_values': torch.from_numpy(values),           # (n_points,)\n",
    "        }\n",
    "\n",
    "\n",
    "# Test data generation\n",
    "coords, values = generate_1d_signal(256, 'sine_mix')\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(coords, values, 'b-', linewidth=2, label='Full signal')\n",
    "\n",
    "# Show sparse sampling\n",
    "sparse_idxs = np.random.choice(256, size=int(256 * 0.2), replace=False)\n",
    "plt.scatter(coords[sparse_idxs], values[sparse_idxs], c='r', s=30, label='Sparse observations (20%)', zorder=10)\n",
    "plt.xlabel('Coordinate')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Example 1D Signal with Sparse Observations')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Field Decoder (SIREN-based)\n",
    "\n",
    "SIREN uses periodic activations (sine) which are well-suited for representing continuous signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    \"\"\"Sine activation with frequency modulation (SIREN layer)\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True, omega_0=30.0, is_first=False):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.linear.in_features, \n",
    "                                           1 / self.linear.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.linear.in_features) / self.omega_0,\n",
    "                                           np.sqrt(6 / self.linear.in_features) / self.omega_0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.omega_0 * self.linear(x))\n",
    "\n",
    "\n",
    "class NeuralFieldDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Field Decoder: f(coords, z) â†’ values\n",
    "    \n",
    "    Uses SIREN architecture conditioned on latent code z\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=64, hidden_dim=128, n_layers=3, omega_0=30.0):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # First layer: coords (1D) + latent (latent_dim) â†’ hidden\n",
    "        self.first_layer = SineLayer(\n",
    "            in_features=1 + latent_dim,\n",
    "            out_features=hidden_dim,\n",
    "            omega_0=omega_0,\n",
    "            is_first=True\n",
    "        )\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            SineLayer(hidden_dim, hidden_dim, omega_0=omega_0)\n",
    "            for _ in range(n_layers - 1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer: hidden â†’ 1 (value)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        # Initialize output layer\n",
    "        with torch.no_grad():\n",
    "            self.output_layer.weight.uniform_(\n",
    "                -np.sqrt(6 / hidden_dim) / omega_0,\n",
    "                np.sqrt(6 / hidden_dim) / omega_0\n",
    "            )\n",
    "    \n",
    "    def forward(self, coords, latent):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coords: (B, N, 1) query coordinates\n",
    "            latent: (B, latent_dim) latent code\n",
    "        \n",
    "        Returns:\n",
    "            values: (B, N, 1) predicted values\n",
    "        \"\"\"\n",
    "        B, N, _ = coords.shape\n",
    "        \n",
    "        # Broadcast latent to all coordinates\n",
    "        latent_expanded = latent.unsqueeze(1).expand(B, N, self.latent_dim)  # (B, N, latent_dim)\n",
    "        \n",
    "        # Concatenate coords with latent\n",
    "        x = torch.cat([coords, latent_expanded], dim=-1)  # (B, N, 1 + latent_dim)\n",
    "        \n",
    "        # Forward through SIREN\n",
    "        x = self.first_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        values = self.output_layer(x)\n",
    "        \n",
    "        return values\n",
    "\n",
    "\n",
    "# Test neural field\n",
    "nf = NeuralFieldDecoder(latent_dim=64, hidden_dim=128, n_layers=3).to(device)\n",
    "test_coords = torch.linspace(0, 1, 100).unsqueeze(0).unsqueeze(-1).to(device)  # (1, 100, 1)\n",
    "test_latent = torch.randn(1, 64).to(device)  # (1, 64)\n",
    "test_output = nf(test_coords, test_latent)\n",
    "print(f\"Neural Field test: coords {test_coords.shape} + latent {test_latent.shape} â†’ output {test_output.shape}\")\n",
    "\n",
    "# Visualize random neural field outputs\n",
    "plt.figure(figsize=(12, 4))\n",
    "coords_np = test_coords[0].cpu().numpy()\n",
    "for i in range(5):\n",
    "    latent = torch.randn(1, 64).to(device)\n",
    "    output = nf(test_coords, latent)\n",
    "    plt.plot(coords_np, output[0].detach().cpu().numpy(), alpha=0.7, label=f'Random latent {i+1}')\n",
    "plt.xlabel('Coordinate')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Neural Field Decoder with Random Latent Codes')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoder: Sparse Observations â†’ Latent Code\n",
    "\n",
    "Simple MLP that encodes sparse observations into a fixed-size latent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: Sparse observations â†’ Latent code\n",
    "    \n",
    "    Uses simple MLP on flattened sparse (coord, value) pairs\n",
    "    \"\"\"\n",
    "    def __init__(self, max_sparse_points=64, latent_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.max_sparse_points = max_sparse_points\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Input: flattened (coord, value) pairs\n",
    "        input_dim = max_sparse_points * 2  # (coord, value) for each point\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sparse_coords, sparse_values):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sparse_coords: (B, n_sparse) observed coordinates\n",
    "            sparse_values: (B, n_sparse) observed values\n",
    "        \n",
    "        Returns:\n",
    "            latent: (B, latent_dim) latent code\n",
    "        \"\"\"\n",
    "        B, n_sparse = sparse_coords.shape\n",
    "        \n",
    "        # Concatenate coords and values\n",
    "        sparse_data = torch.stack([sparse_coords, sparse_values], dim=-1)  # (B, n_sparse, 2)\n",
    "        \n",
    "        # Pad to max_sparse_points if needed\n",
    "        if n_sparse < self.max_sparse_points:\n",
    "            padding = torch.zeros(B, self.max_sparse_points - n_sparse, 2, device=sparse_data.device)\n",
    "            sparse_data = torch.cat([sparse_data, padding], dim=1)\n",
    "        \n",
    "        # Flatten and encode\n",
    "        sparse_flat = sparse_data.view(B, -1)  # (B, max_sparse_points * 2)\n",
    "        latent = self.encoder(sparse_flat)  # (B, latent_dim)\n",
    "        \n",
    "        return latent\n",
    "\n",
    "\n",
    "# Test encoder\n",
    "encoder = SparseEncoder(max_sparse_points=64, latent_dim=64).to(device)\n",
    "test_sparse_coords = torch.rand(4, 51).to(device)  # Batch of 4, 51 sparse points\n",
    "test_sparse_values = torch.rand(4, 51).to(device)\n",
    "test_latent = encoder(test_sparse_coords, test_sparse_values)\n",
    "print(f\"Encoder test: sparse coords {test_sparse_coords.shape} + values {test_sparse_values.shape} â†’ latent {test_latent.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Model: Encoder + Neural Field (No Diffusion Yet)\n",
    "\n",
    "First, let's train the encoder + neural field to reconstruct signals from sparse observations.\n",
    "This validates that the architecture can learn the mapping before adding diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseToFieldModel(nn.Module):\n",
    "    \"\"\"Complete model: Sparse observations â†’ Latent â†’ Continuous field\"\"\"\n",
    "    \n",
    "    def __init__(self, max_sparse_points=64, latent_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = SparseEncoder(max_sparse_points, latent_dim, hidden_dim)\n",
    "        self.decoder = NeuralFieldDecoder(latent_dim, hidden_dim=128, n_layers=3)\n",
    "    \n",
    "    def forward(self, sparse_coords, sparse_values, query_coords):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sparse_coords: (B, n_sparse) observed coordinates\n",
    "            sparse_values: (B, n_sparse) observed values\n",
    "            query_coords: (B, n_query, 1) coordinates to query\n",
    "        \n",
    "        Returns:\n",
    "            pred_values: (B, n_query, 1) predicted values\n",
    "            latent: (B, latent_dim) latent code (for diffusion later)\n",
    "        \"\"\"\n",
    "        latent = self.encoder(sparse_coords, sparse_values)\n",
    "        pred_values = self.decoder(query_coords, latent)\n",
    "        return pred_values, latent\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_sparse_to_field(model, train_loader, epochs=50, lr=1e-4):\n",
    "    \"\"\"Train encoder + decoder on sparse reconstruction task\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            sparse_coords = batch['sparse_coords'].to(device)  # (B, n_sparse)\n",
    "            sparse_values = batch['sparse_values'].to(device)  # (B, n_sparse)\n",
    "            full_coords = batch['full_coords'].to(device).unsqueeze(-1)  # (B, n_full, 1)\n",
    "            full_values = batch['full_values'].to(device).unsqueeze(-1)  # (B, n_full, 1)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_values, latent = model(sparse_coords, sparse_values, full_coords)\n",
    "            \n",
    "            # MSE loss on full signal reconstruction\n",
    "            loss = F.mse_loss(pred_values, full_values)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.6f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = Sparse1DDataset(n_samples=1000, n_points=256, sparsity=0.2)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = SparseToFieldModel(max_sparse_points=64, latent_dim=64, hidden_dim=256).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train\n",
    "losses = train_sparse_to_field(model, train_loader, epochs=20, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation: Visualize Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training Loss: Sparse to Field Reconstruction')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize reconstructions\n",
    "model.eval()\n",
    "test_dataset = Sparse1DDataset(n_samples=5, n_points=256, sparsity=0.2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 3))\n",
    "with torch.no_grad():\n",
    "    for i, ax in enumerate(axes):\n",
    "        sample = test_dataset[i]\n",
    "        sparse_coords = sample['sparse_coords'].unsqueeze(0).to(device)\n",
    "        sparse_values = sample['sparse_values'].unsqueeze(0).to(device)\n",
    "        full_coords = sample['full_coords'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        full_values = sample['full_values'].cpu().numpy()\n",
    "        \n",
    "        # Predict\n",
    "        pred_values, _ = model(sparse_coords, sparse_values, full_coords)\n",
    "        pred_values = pred_values[0].squeeze().cpu().numpy()\n",
    "        \n",
    "        # Plot\n",
    "        coords_np = sample['full_coords'].numpy()\n",
    "        ax.plot(coords_np, full_values, 'b-', linewidth=2, alpha=0.7, label='Ground truth')\n",
    "        ax.plot(coords_np, pred_values, 'r--', linewidth=2, alpha=0.7, label='Reconstruction')\n",
    "        ax.scatter(\n",
    "            sample['sparse_coords'].numpy(), \n",
    "            sample['sparse_values'].numpy(), \n",
    "            c='green', s=30, zorder=10, label='Sparse obs'\n",
    "        )\n",
    "        ax.set_xlabel('Coordinate')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.set_title(f'Test Signal {i+1}')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute metrics\n",
    "mse_errors = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        sample = test_dataset[i]\n",
    "        sparse_coords = sample['sparse_coords'].unsqueeze(0).to(device)\n",
    "        sparse_values = sample['sparse_values'].unsqueeze(0).to(device)\n",
    "        full_coords = sample['full_coords'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        full_values = sample['full_values'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        \n",
    "        pred_values, _ = model(sparse_coords, sparse_values, full_coords)\n",
    "        mse = F.mse_loss(pred_values, full_values).item()\n",
    "        mse_errors.append(mse)\n",
    "\n",
    "print(f\"\\nTest MSE: {np.mean(mse_errors):.6f} Â± {np.std(mse_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps: Add Diffusion Model\n",
    "\n",
    "Now that we have a working encoder + neural field decoder, the next step is to add a diffusion model on the latent codes.\n",
    "\n",
    "### Plan:\n",
    "1. **Extract latent codes** from trained encoder on full dataset\n",
    "2. **Train DDPM** on latent space\n",
    "3. **Generation**: Sample z ~ p(z) from diffusion â†’ Decode with neural field\n",
    "4. **Conditional generation**: Condition diffusion on sparse observations\n",
    "\n",
    "### Why Diffusion on Latents?\n",
    "- **Smaller space**: 64D latent vs 256D signal\n",
    "- **Semantic**: Latents capture signal structure\n",
    "- **Fast sampling**: Fewer diffusion steps needed\n",
    "\n",
    "This will be implemented in the next notebook: `02_approach1_with_diffusion.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Implemented**:\n",
    "- SIREN-based neural field decoder for continuous 1D signal representation\n",
    "- Sparse observation encoder (MLP-based)\n",
    "- End-to-end training on sparse-to-dense reconstruction\n",
    "\n",
    "âœ… **Validated**:\n",
    "- Neural field can represent continuous signals from latent codes\n",
    "- Encoder can compress sparse observations into meaningful latents\n",
    "- Model successfully reconstructs full signals from 20% sparse observations\n",
    "\n",
    "ðŸ“‹ **Next Steps**:\n",
    "1. Add DDPM diffusion model on latent space\n",
    "2. Train diffusion for unconditional generation\n",
    "3. Add conditioning on sparse observations\n",
    "4. Test arbitrary-resolution querying (super-resolution)\n",
    "5. Extend to 2D images (CIFAR-10 or MNIST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
