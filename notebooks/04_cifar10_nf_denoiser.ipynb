{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Sparse Reconstruction: Neural Field as Denoiser\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Approach**: Gaussian Random Field Denoising (Your Idea!)\n",
    "\n",
    "**Key Concept**: Start with Gaussian noise at output pixel locations, progressively denoise using neural field while keeping input pixels clean and fixed.\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Step T: Gaussian Noise at Output Locations\n",
    "        + Clean Input Pixels (FIXED)\n",
    "        ‚Üì\n",
    "Neural Field Denoiser f_Œ∏(noisy_out, clean_in, coords, t)\n",
    "        ‚Üì\n",
    "Step T-1: Less Noisy Output\n",
    "          + Clean Input Pixels (FIXED)\n",
    "        ‚Üì\n",
    "        ...\n",
    "        ‚Üì\n",
    "Step 0: Clean Output Predictions!\n",
    "```\n",
    "\n",
    "## Theory: Direct Denoising with Fixed Conditioning\n",
    "\n",
    "### Forward Process (Add Noise to Output Only)\n",
    "$$x_t^{out} = \\sqrt{\\bar{\\alpha}_t} \\cdot x_0^{out} + \\sqrt{1 - \\bar{\\alpha}_t} \\cdot \\epsilon$$\n",
    "\n",
    "where $x_0^{out}$ are clean output pixels, $\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "\n",
    "**Key**: Input pixels $x^{in}$ remain **clean throughout**!\n",
    "\n",
    "### Reverse Process (Denoise Output)\n",
    "$$x_0^{pred} = f_\\theta(x_t^{out}, x^{in}, \\text{coords}, t)$$\n",
    "\n",
    "Neural field predicts clean output values from:\n",
    "- Noisy output pixels (changing each step)\n",
    "- Clean input pixels (fixed conditioning)\n",
    "- Coordinates (spatial information)\n",
    "- Timestep t (noise level)\n",
    "\n",
    "### Training Objective\n",
    "$$\\mathcal{L} = \\mathbb{E}_{t, x_0, \\epsilon} \\left[\\| f_\\theta(x_t^{out}, x^{in}, \\text{coords}, t) - x_0^{out} \\|^2 \\right]$$\n",
    "\n",
    "**Direct prediction loss** - predict clean from noisy!\n",
    "\n",
    "### Why This Approach?\n",
    "- ‚úÖ **Most intuitive**: Gaussian random field ‚Üí clean field\n",
    "- ‚úÖ **Single objective**: Predict clean values directly\n",
    "- ‚úÖ **Clear separation**: Input clean, output noisy\n",
    "- ‚úÖ **Fast sampling**: DDIM possible (10-50 steps)\n",
    "- ‚úÖ **Flexible**: Can use DDPM or DDIM sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# Import shared components\n",
    "from core.neural_fields.perceiver import PerceiverIO, FourierFeatures\n",
    "from core.sparse.cifar10_sparse import SparseCIFAR10Dataset\n",
    "from core.sparse.metrics import MetricsTracker, print_metrics, visualize_predictions\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Schedule (Same as DDPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def cosine_beta_schedule(timesteps, s=0.008):\n    \"\"\"Cosine schedule from Improved DDPM\"\"\"\n    steps = timesteps + 1\n    x = torch.linspace(0, timesteps, steps)\n    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    return torch.clip(betas, 0.0001, 0.9999)\n\n\nclass DiffusionSchedule:\n    \"\"\"DDPM diffusion schedule\"\"\"\n    def __init__(self, timesteps=1000, beta_schedule='cosine'):\n        self.timesteps = timesteps\n        \n        if beta_schedule == 'cosine':\n            betas = cosine_beta_schedule(timesteps)\n        else:\n            betas = torch.linspace(0.0001, 0.02, timesteps)\n        \n        alphas = 1.0 - betas\n        alphas_cumprod = torch.cumprod(alphas, dim=0)\n        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n        \n        self.betas = betas\n        self.alphas = alphas\n        self.alphas_cumprod = alphas_cumprod\n        self.alphas_cumprod_prev = alphas_cumprod_prev\n        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n        self.sqrt_recip_alphas_cumprod = torch.sqrt(1.0 / alphas_cumprod)\n        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / alphas_cumprod - 1)\n        \n        # Posterior variance for DDPM\n        self.posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n        self.posterior_log_variance = torch.log(torch.clamp(self.posterior_variance, min=1e-20))\n    \n    def to(self, device):\n        \"\"\"Move all tensors to device\"\"\"\n        self.betas = self.betas.to(device)\n        self.alphas = self.alphas.to(device)\n        self.alphas_cumprod = self.alphas_cumprod.to(device)\n        self.alphas_cumprod_prev = self.alphas_cumprod_prev.to(device)\n        self.sqrt_alphas_cumprod = self.sqrt_alphas_cumprod.to(device)\n        self.sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device)\n        self.sqrt_recip_alphas_cumprod = self.sqrt_recip_alphas_cumprod.to(device)\n        self.sqrt_recipm1_alphas_cumprod = self.sqrt_recipm1_alphas_cumprod.to(device)\n        self.posterior_variance = self.posterior_variance.to(device)\n        self.posterior_log_variance = self.posterior_log_variance.to(device)\n        return self\n\n\n# Visualize\nschedule = DiffusionSchedule(timesteps=1000)\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 3, 1)\nplt.plot(schedule.betas.numpy())\nplt.title('Œ≤_t')\nplt.xlabel('Timestep')\nplt.grid(alpha=0.3)\n\nplt.subplot(1, 3, 2)\nplt.plot(schedule.alphas_cumprod.numpy())\nplt.title('·æ±_t (Signal Strength)')\nplt.xlabel('Timestep')\nplt.grid(alpha=0.3)\n\nplt.subplot(1, 3, 3)\nplt.plot(schedule.sqrt_alphas_cumprod.numpy(), label='‚àö·æ±_t')\nplt.plot(schedule.sqrt_one_minus_alphas_cumprod.numpy(), label='‚àö(1-·æ±_t)')\nplt.title('Noise Mixing')\nplt.xlabel('Timestep')\nplt.legend()\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Field Denoiser Architecture\n",
    "\n",
    "Key idea: Input pixels stay clean, only output pixels are noisy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"Sinusoidal time embedding for noise level\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([emb.sin(), emb.cos()], dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class NFDenoiser(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Field Denoiser: Gaussian Random Field ‚Üí Clean Field\n",
    "    \n",
    "    f_Œ∏(noisy_output, clean_input, coords, t) ‚Üí clean_output\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_latents=512,\n",
    "        latent_dim=512,\n",
    "        num_fourier_feats=256,\n",
    "        num_blocks=6,\n",
    "        num_heads=8,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Perceiver IO backbone\n",
    "        self.perceiver = PerceiverIO(\n",
    "            input_channels=3,\n",
    "            output_channels=3,\n",
    "            num_latents=num_latents,\n",
    "            latent_dim=latent_dim,\n",
    "            num_fourier_feats=num_fourier_feats,\n",
    "            num_blocks=num_blocks,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed = SinusoidalTimeEmbedding(latent_dim)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(latent_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Marker for input vs output pixels\n",
    "        self.marker_embed = nn.Embedding(2, 3)  # 0=input, 1=output\n",
    "    \n",
    "    def forward(self, noisy_output_values, output_coords, t, input_coords, input_values):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            noisy_output_values: (B, N_out, 3) NOISY output pixel values\n",
    "            output_coords: (B, N_out, 2) output pixel coordinates\n",
    "            t: (B,) continuous timesteps\n",
    "            input_coords: (B, N_in, 2) input pixel coordinates\n",
    "            input_values: (B, N_in, 3) CLEAN input pixel values\n",
    "        \n",
    "        Returns:\n",
    "            clean_pred: (B, N_out, 3) predicted CLEAN output values\n",
    "        \"\"\"\n",
    "        B, N_in = input_coords.shape[0], input_coords.shape[1]\n",
    "        N_out = output_coords.shape[1]\n",
    "        \n",
    "        # Time embedding\n",
    "        t_emb = self.time_mlp(self.time_embed(t))  # (B, latent_dim)\n",
    "        \n",
    "        # Add time information to pixel values (broadcast to RGB channels)\n",
    "        time_signal = t_emb[:, :3].unsqueeze(1)  # (B, 1, 3)\n",
    "        \n",
    "        # IMPORTANT: Input pixels are CLEAN (no noise added)\n",
    "        #            Output pixels are NOISY (progressively denoised)\n",
    "        input_values_t = input_values + time_signal  # Add time to clean input\n",
    "        noisy_output_values_t = noisy_output_values + time_signal  # Add time to noisy output\n",
    "        \n",
    "        # Concatenate all pixels (input=clean, output=noisy)\n",
    "        all_coords = torch.cat([input_coords, output_coords], dim=1)  # (B, N_in+N_out, 2)\n",
    "        all_values = torch.cat([input_values_t, noisy_output_values_t], dim=1)  # (B, N_in+N_out, 3)\n",
    "        \n",
    "        # Predict CLEAN values at output coordinates\n",
    "        clean_pred = self.perceiver(all_coords, all_values, output_coords)\n",
    "        \n",
    "        return clean_pred\n",
    "\n",
    "\n",
    "# Test denoiser\n",
    "model = NFDenoiser().to(device)\n",
    "test_noisy = torch.randn(4, 204, 3).to(device)\n",
    "test_output_coords = torch.rand(4, 204, 2).to(device)\n",
    "test_t = torch.rand(4).to(device) * 1000\n",
    "test_input_coords = torch.rand(4, 204, 2).to(device)\n",
    "test_input_values = torch.rand(4, 204, 3).to(device)\n",
    "\n",
    "test_pred = model(test_noisy, test_output_coords, test_t, test_input_coords, test_input_values)\n",
    "print(f\"Denoiser test: {test_pred.shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training: Direct Clean Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_denoiser(\n    model,\n    train_loader,\n    schedule,\n    epochs=100,\n    lr=1e-4,\n    device='cuda'\n):\n    \"\"\"Train neural field denoiser\"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n    \n    losses = []\n    \n    model.train()\n    for epoch in range(epochs):\n        epoch_loss = 0\n        \n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            input_coords = batch['input_coords'].to(device)\n            input_values = batch['input_values'].to(device)  # CLEAN (fixed)\n            output_coords = batch['output_coords'].to(device)\n            output_values = batch['output_values'].to(device)  # x_0 (target)\n            \n            B = input_coords.shape[0]\n            \n            # Sample random timestep\n            t = torch.randint(0, schedule.timesteps, (B,), device=device).float()\n            \n            # Add noise to OUTPUT ONLY: x_t = ‚àö·æ±_t * x_0 + ‚àö(1-·æ±_t) * Œµ\n            noise = torch.randn_like(output_values)\n            sqrt_alpha_t = schedule.sqrt_alphas_cumprod[t.long()].view(B, 1, 1)\n            sqrt_one_minus_alpha_t = schedule.sqrt_one_minus_alphas_cumprod[t.long()].view(B, 1, 1)\n            \n            noisy_output = sqrt_alpha_t * output_values + sqrt_one_minus_alpha_t * noise\n            \n            # Predict CLEAN output from noisy output + clean input\n            pred_clean = model(noisy_output, output_coords, t, input_coords, input_values)\n            \n            # Loss: predict clean values\n            loss = F.mse_loss(pred_clean, output_values)\n            \n            # Backward\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n        \n        avg_loss = epoch_loss / len(train_loader)\n        losses.append(avg_loss)\n        scheduler.step()\n        \n        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.6f}, LR = {scheduler.get_last_lr()[0]:.6f}\")\n        \n        # Save checkpoint\n        if (epoch + 1) % 10 == 0:\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': avg_loss,\n            }, f'nf_denoiser_epoch_{epoch+1}.pt')\n    \n    return losses\n\n\n# Create dataset\nprint(\"Loading CIFAR-10...\")\ntrain_dataset = SparseCIFAR10Dataset(\n    root='../data',\n    train=True,\n    input_ratio=0.2,\n    output_ratio=0.2,\n    download=True,\n    seed=42\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n\nprint(f\"Dataset size: {len(train_dataset)}\")\nprint(f\"Batches: {len(train_loader)}\")\n\n# Initialize\nmodel = NFDenoiser(\n    num_latents=512,\n    latent_dim=512,\n    num_fourier_feats=256,\n    num_blocks=6,\n    num_heads=8\n).to(device)\n\nschedule = DiffusionSchedule(timesteps=1000, beta_schedule='cosine').to(device)\n\n# Train\nprint(\"\\nStarting training...\")\nlosses = train_denoiser(model, train_loader, schedule, epochs=100, lr=1e-4, device=device)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sampling: DDPM or DDIM\n",
    "\n",
    "We implement DDIM for faster sampling (10-50 steps vs 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef ddim_sample(\n    model,\n    schedule,\n    output_coords,\n    input_coords,\n    input_values,\n    num_steps=50,\n    eta=0.0,  # 0=DDIM, 1=DDPM\n    device='cuda'\n):\n    \"\"\"\n    DDIM sampling (faster than DDPM)\n    \n    Args:\n        model: Trained denoiser\n        schedule: Diffusion schedule\n        output_coords: (B, N_out, 2)\n        input_coords: (B, N_in, 2)\n        input_values: (B, N_in, 3) CLEAN (conditioning)\n        num_steps: Sampling steps (50 is good)\n        eta: Stochasticity (0=deterministic DDIM)\n    \n    Returns:\n        x_0: (B, N_out, 3) predicted clean values\n    \"\"\"\n    B = output_coords.shape[0]\n    N_out = output_coords.shape[1]\n    \n    # Start from Gaussian random field\n    x_t = torch.randn(B, N_out, 3, device=device)\n    \n    # Uniform timestep schedule\n    timesteps = torch.linspace(schedule.timesteps - 1, 0, num_steps).long()\n    \n    for i, t_idx in enumerate(tqdm(timesteps, desc=\"Sampling (DDIM)\")):\n        t = torch.full((B,), t_idx.item(), device=device, dtype=torch.float)\n        \n        # Predict x_0 from x_t\n        x_0_pred = model(x_t, output_coords, t, input_coords, input_values)\n        \n        if i < len(timesteps) - 1:\n            # Get next timestep\n            t_next = timesteps[i + 1]\n            \n            # DDIM update\n            alpha_t = schedule.alphas_cumprod[t_idx]\n            alpha_t_next = schedule.alphas_cumprod[t_next]\n            \n            # Predicted noise\n            eps_pred = (x_t - torch.sqrt(alpha_t) * x_0_pred) / torch.sqrt(1 - alpha_t)\n            \n            # DDIM step\n            x_t = (\n                torch.sqrt(alpha_t_next) * x_0_pred +\n                torch.sqrt(1 - alpha_t_next) * eps_pred\n            )\n            \n            # Optional: add stochasticity (eta > 0)\n            if eta > 0:\n                sigma_t = eta * torch.sqrt(\n                    (1 - alpha_t_next) / (1 - alpha_t) * (1 - alpha_t / alpha_t_next)\n                )\n                noise = torch.randn_like(x_t)\n                x_t = x_t + sigma_t * noise\n        else:\n            # Final step\n            x_t = x_0_pred\n    \n    return torch.clamp(x_t, 0, 1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation with Unified Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training Loss: Neural Field Denoiser')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_dataset = SparseCIFAR10Dataset(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    input_ratio=0.2,\n",
    "    output_ratio=0.2,\n",
    "    download=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "model.eval()\n",
    "tracker = MetricsTracker()\n",
    "\n",
    "for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "    input_coords = batch['input_coords'].to(device)\n",
    "    input_values = batch['input_values'].to(device)\n",
    "    output_coords = batch['output_coords'].to(device)\n",
    "    output_values = batch['output_values'].to(device)\n",
    "    \n",
    "    # Sample predictions (DDIM with 50 steps)\n",
    "    pred_values = ddim_sample(\n",
    "        model, schedule, output_coords, input_coords, input_values,\n",
    "        num_steps=50, eta=0.0, device=device\n",
    "    )\n",
    "    \n",
    "    tracker.update(pred_values, output_values)\n",
    "\n",
    "# Print results\n",
    "results = tracker.compute()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEURAL FIELD DENOISER - Test Results\")\n",
    "print(\"=\"*50)\n",
    "print_metrics(results)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "sample_batch = next(iter(test_loader))\n",
    "input_coords = sample_batch['input_coords'].to(device)\n",
    "input_values = sample_batch['input_values'].to(device)\n",
    "output_coords = sample_batch['output_coords'].to(device)\n",
    "output_values = sample_batch['output_values'].to(device)\n",
    "full_images = sample_batch['full_image'].to(device)\n",
    "\n",
    "# Generate predictions\n",
    "pred_values = ddim_sample(\n",
    "    model, schedule, output_coords, input_coords, input_values,\n",
    "    num_steps=50, eta=0.0, device=device\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig = visualize_predictions(\n",
    "    input_coords, input_values,\n",
    "    output_coords, pred_values, output_values,\n",
    "    full_images, n_samples=4\n",
    ")\n",
    "plt.suptitle('Neural Field Denoiser: Predictions vs Ground Truth', fontsize=14, y=1.02)\n",
    "plt.savefig('nf_denoiser_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ‚úÖ Implemented\n",
    "- Gaussian Random Field denoising (your idea!)\n",
    "- Direct clean prediction objective\n",
    "- DDIM sampling (50 steps)\n",
    "- Fixed clean input conditioning\n",
    "\n",
    "### üìä Results\n",
    "See metrics above for:\n",
    "- MSE/MAE on output pixels\n",
    "- PSNR/SSIM on full images\n",
    "\n",
    "### ‚öñÔ∏è Strengths & Weaknesses\n",
    "\n",
    "**Strengths**:\n",
    "- ‚úÖ **Most intuitive approach**: Gaussian noise ‚Üí clean field\n",
    "- ‚úÖ **Simple training**: Single MSE loss on clean prediction\n",
    "- ‚úÖ **Fast sampling**: DDIM with 50 steps (vs 1000 for score-based)\n",
    "- ‚úÖ **Clear separation**: Input always clean, output denoised\n",
    "- ‚úÖ **Flexible**: Works with DDPM or DDIM\n",
    "\n",
    "**Potential Weaknesses**:\n",
    "- ‚ö†Ô∏è May need more steps for very high quality\n",
    "- ‚ö†Ô∏è Less theoretically principled than score-based\n",
    "\n",
    "### üîÑ Next\n",
    "Compare with:\n",
    "- Notebook 3: Score-Based (already done)\n",
    "- Notebook 5: Flow Matching (next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}